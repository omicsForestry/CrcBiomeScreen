---
title: "CrcBiomeScreen: Colorectal Cancer Microbiome Screening and Analysis"
author: "Chengxin Li"
date: "`r Sys.Date()`"
output: 
    BiocStyle::html_document:
    toc: true
    toc_float: true
vignette: >
  %\VignetteIndexEntry{CrcBiomeScreen}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  crop = NULL
)
```

# Introduction

Colorectal cancer (CRC) is one of the most common cancers worldwide, and the gut microbiome has been increasingly recognized as a key factor in CRC development and progression. The identification of microbiome-based biomarkers for CRC screening has great potential for early detection and improved patient outcomes.

`CrcBiomeScreen` is an R package designed specifically for colorectal cancer microbiome screening and analysis. The package provides a comprehensive workflow that integrates data preprocessing, normalization, machine learning-based classification, and model validation to identify microbiome signatures associated with CRC.

The main features of `CrcBiomeScreen` include:

- **Data preprocessing**: Taxonomic level splitting and filtering
- **Normalization methods**: Support for two normalization approaches including GMPR and TSS
- **Machine learning models**: Random Forest and XGBoost classifiers
- **Model validation**: Cross-validation and external validation capabilities
- **Quality control**: Built-in quality control using multidimensional scaling
- **Streamlined workflow**: One-function screening pipeline

## Installation

Install the development version of the package from GitHub:

```{r, eval = FALSE}
install.packages(c("remotes"))
remotes::install_github("iChronostasis/CrcBiomeScreen", force = TRUE)
```

Load `CrcBiomeScreen` into the R session:

```{r, eval = FALSE}
library(CrcBiomeScreen)
```

# Getting started

The core workflow of `CrcBiomeScreen` involves several key steps: data loading and pre-processing, normalization, model training, evaluation, and validation. All functions are designed to work with the `CrcBiomeScreenObject`, which is the main data structure used throughout the package.

## Data preparation

First, we need to load the example data and create a `CrcBiomeScreenObject` This object is the primary input for all downstream functions in the package.

We offer two methods for preparing your data. You only need to use one of the following examples, depending on the format of your input data.

The first example below, which uses the Thomas_2018_RelativeAbundance dataset, is the one we will be using for the subsequent steps in this vignette. It represents a typical use case with a more complex dataset. The second example with NHSBCSP_screeningData is included to show an alternative input format for simpler datasets, demonstrating that the function can handle various data structures.

```{r, eval = FALSE}
# Set working directory
# setwd("/home/CRCscreening/CRCscreening-Workflow/")
# List available datasets in the package
data(package = "CrcBiomeScreen")

# Load the toy dataset from curatedMetagenomicData
data(Thomas_2018_RelativeAbundance, package = "CrcBiomeScreen")

# Create the CrcBiomeScreenObject
CrcBiomeScreenObject <- CreateCrcBiomeScreenObject(
  RelativeAbundance = Thomas_2018_RelativeAbundance[[1]]@assays@data@listData$relative_abundance,
  TaxaData = Thomas_2018_RelativeAbundance[[1]]@rowLinks$nodeLab,
  SampleData = Thomas_2018_RelativeAbundance[[1]]@colData
)

# Load the simple toy dataset from curatedMetagenomicData
data(NHSBCSP_screeningData, package = "CrcBiomeScreen")

# Create the CrcBiomeScreenObject for simple toy data
CrcBiomeScreenObject_NHSBCSP_screeningData <- CreateCrcBiomeScreenObject(
  AbsoluteAbundance = NHSBCSP_screeningData[,-c(1:2,646:647)],
  TaxaData = colnames(NHSBCSP_screeningData[,-c(1:2,646:647)]),
  SampleData = NHSBCSP_screeningData[,c(1:2,646:647)]
)
```

## Taxonomic data processing

The package offers robust functions to process raw taxonomic strings, splitting them into multiple hierarchical levels and allowing you to filter to a specific taxonomic rank. This ensures your data is clean and ready for downstream analysis.

### Supported formats  
Currently, the function supports multiple formats of taxonomic strings, including **MetaPhlAn**, **QIIME**, **SILVA**, etc.  
Users do not need to manually specify the delimiter (`;`, `.`, `|`, `_`), since the function automatically detects the correct separator.  

### Original taxa column  
For reproducibility and traceability, the output contains an additional column `OriginalTaxa` that preserves the original input string.  

### Special handling of *uncultured* and *unclassified*  
If a taxonomic entry at a given rank is `"uncultured"` or `"unclassified"`, the function appends this label to the higher-level taxa.  

For example:

| Input (Start...End) | Processed Output (Genus) |
| :--- | :--- |
| `D_...D_3__Ruminococcaceae.D_4__uncultured` | `Ruminococcaceae_uncultured` |
| `k__...f__Enterobacteriaceae; g__unclassified` | `Enterobacteriaceae_unclassified` |

### Choosing a Taxonomic Level

You don't have to be limited to just the genus level. Use the `KeepTaxonomicLevel()` function to select the rank you need, whether it's **family**, **genus**, or **species**. The function will automatically group taxa at the specified level. For the situation where there are two levels of unclassified, it will retain one level with unclassified.

### Handling Data Without Taxonomic Strings

For data like **ASVs** or **OTUs** that do not contain taxonomic information in their names, you can use the `LoadTaxaTable()` function to import a separate table that maps each sequence ID to its full taxonomic lineage. This provides maximum flexibility for any type of input data. The use of this function can be seen in the documentation of the function. 

### Example  

```{r, eval = FALSE}
# Split the taxa into multiple levels
CrcBiomeScreenObject <- SplitTaxas(CrcBiomeScreenObject)

# Keep only the genus level data
CrcBiomeScreenObject <- KeepTaxonomicLevel(CrcBiomeScreenObject,level = "Genus")

# Inspect processed data
head(CrcBiomeScreenObject$TaxaData)
```

## Data normalization

`CrcBiomeScreen` supports multiple normalization methods. Here we demonstrate both GMPR and TSS normalization:

```{r, eval = FALSE}
# Normalize using GMPR (Geometric Mean of Pairwise Ratios)
CrcBiomeScreenObject <- NormalizeData(CrcBiomeScreenObject, method = "GMPR", level = "Genus")

# Normalize using TSS (Total Sum Scaling)
CrcBiomeScreenObject <- NormalizeData(CrcBiomeScreenObject, method = "TSS", level = "Genus")
```

**Note**: GMPR normalization is generally recommended for microbiome data as it is more robust to compositional effects and outliers compared to TSS normalization.

# Validation data preparation

For robust model evaluation, it's important to prepare independent validation data:

```{r, eval = FALSE}
# Load validation data
data("ZellerG_2014_RelativeAbundance")

# Create CrcBiomeScreenObject for validation data
ValidationData <- CreateCrcBiomeScreenObject(
  RelativeAbundance = ZellerG_2014_RelativeAbundance[[1]]@assays@data@listData$relative_abundance,
  TaxaData = ZellerG_2014_RelativeAbundance[[1]]@rowLinks$nodeLab,
  SampleData = ZellerG_2014_RelativeAbundance[[1]]@colData
)

# Process validation data similarly to training data
ValidationData <- SplitTaxas(ValidationData)
ValidationData <- KeepTaxonomicLevel(ValidationData,level = "Genus")
ValidationData <- NormalizeData(ValidationData, method = "GMPR", level = "Genus")

# Ensure consistent features between training and validation data
ValidationData$NormalizedData <- ValidationData$NormalizedData[, 
  colnames(ValidationData$NormalizedData) %in% colnames(CrcBiomeScreenObject$NormalizedData)]

CrcBiomeScreenObject$NormalizedData <- CrcBiomeScreenObject$NormalizedData[, 
  colnames(CrcBiomeScreenObject$NormalizedData) %in% colnames(ValidationData$NormalizedData)]
```

# Model training and evaluation

## Data filtering and splitting

Before model training, we need to filter the data to include only CRC and control samples, then split into training and test sets:

```{r, eval = FALSE}
# Check the available labels in the data
table(CrcBiomeScreenObject$SampleData$study_condition)

# Filter data to keep only CRC and control samples
CrcBiomeScreenObject <- FilterDataSet(
  CrcBiomeScreenObject,
  label = c("CRC", "control"),
  condition_col = "study_condition"
)

# Verify the filtering results
table(CrcBiomeScreenObject$SampleData$study_condition)

# Split data into training (70%) and test (30%) sets
CrcBiomeScreenObject <- SplitDataSet(
  CrcBiomeScreenObject, 
  label = c("control", "CRC"), 
  partition = 0.7
)
```

## Quality control

Quality control using classical multidimensional scaling can help identify potential batch effects or outliers:

```{r, eval = FALSE}
# Perform quality control using cmdscale
CrcBiomeScreenObject <- qcByCmdscale(
  CrcBiomeScreenObject,
  TaskName = "Normalize_ToyData_filtered_qc",
  normalize_method = "GMPR",
  plot = FALSE
)

# Check class balance in the training data
checkClassBalance(CrcBiomeScreenObject$ModelData$TrainLabel)
```

## Model training

`CrcBiomeScreen` supports two machine learning algorithms: Random Forest and XGBoost. Both models can be trained with class balancing to handle imbalanced datasets:

```{r, eval = FALSE}
# Train Random Forest model
CrcBiomeScreenObject <- TrainModels(
  CrcBiomeScreenObject,
  model_type = "RF",
  TaskName = "ToyData_RF",
  ClassBalance = TRUE,
  TrueLabel = "CRC",
  num_cores = 10
)

# Train XGBoost model
CrcBiomeScreenObject <- TrainModels(
  CrcBiomeScreenObject,
  model_type = "XGBoost",
  TaskName = "ToyData_XGBoost",
  ClassBalance = TRUE,
  TrueLabel = "CRC",
  num_cores = 10
)
```

## Model evaluation

Evaluate the trained models on the test set:

```{r, eval = FALSE}
# Evaluate Random Forest model
CrcBiomeScreenObject <- EvaluateModel(
  CrcBiomeScreenObject,
  model_type = "RF",
  TaskName = "ToyData_RF_Test",
  TrueLabel = "CRC",
  PlotAUC = TRUE
)

# Evaluate XGBoost model
CrcBiomeScreenObject <- EvaluateModel(
  CrcBiomeScreenObject,
  model_type = "XGBoost",
  TaskName = "ToyData_XGBoost_Test",
  TrueLabel = "CRC",
  PlotAUC = TRUE
)
```

The evaluation will generate ROC curves and calculate performance metrics such as AUC, sensitivity, and specificity.

# External validation

To ensure the robustness and generalizability of the trained models, external validation on independent datasets is crucial:

```{r, eval = FALSE}
# Filter validation data
ValidationData_filtered <- FilterDataSet(
  ValidationData,
  label = c("CRC", "control"),
  condition_col = "study_condition"
)

# Quality control for validation data
ValidationData_filtered_qc <- qcByCmdscale(
  CrcBiomeScreenObject = ValidationData_filtered,
  TaskName = "Normalize_ValidationData_filtered_qc",
  normalize_method = "GMPR",
  plot = FALSE
)

# Validate Random Forest model on external data
ValidationData_filtered_qc <- ValidateModelOnData(
  CrcBiomeScreenObject,
  model_type = "RF",
  ValidationData = ValidationData_filtered_qc,
  TaskName = "ValidationData_RF_Validation",
  TrueLabel = "CRC",
  PlotAUC = TRUE
)

# Validate XGBoost model on external data
ValidationData_filtered_qc <- ValidateModelOnData(
  CrcBiomeScreenObject,
  model_type = "XGBoost",
  ValidationData = ValidationData_filtered_qc,
  TaskName = "ValidationData_XGBoost_Validation",
  TrueLabel = "CRC",
  PlotAUC = TRUE
)
```

# Prediction & Evaluation

Once you've trained a model, you'll want to apply it to new data and assess its performance. Our package offers a streamlined, two-step process for this: first, generate predictions on your new dataset, and then, if true labels are available, evaluate the model's accuracy. This modular approach allows for flexibility, whether you're predicting outcomes for unknown samples or measuring model quality on a validation set.

## Step 1: Predict on New Data
Use the PredictCrcBiomeScreen() function to generate prediction probabilities for your new dataset. This function takes your trained CrcBiomeScreenObject and the new data, returning the raw prediction scores for each sample.

```{r, eval = FALSE}
# Assuming 'CrcBiomeScreenObject' contains a trained XGBoost model
# and 'MyNewData' is your new dataset (e.g., another CrcBiomeScreenObject or a data frame).

# Generate predictions for the new dataset
ValidationData_filtered_qc$PredictResult$XGBoost <- PredictCrcBiomeScreen(
    CrcBiomeScreenObject, 
    newdata = ValidationData_filtered_qc$NormalizedData, # Use the appropriate data slot from your new data
    model_type = "XGBoost"
)
# Inspect the predictions
head(ValidationData_filtered_qc$PredictResult$XGBoost)
predictions <- ValidationData_filtered_qc$PredictResult$XGBoost
```

## Step 2: Evaluate Model Performance
If your new dataset includes known true labels, you can evaluate the model's performance using the EvaluateCrcBiomeScreen() function. This function takes the predictions generated in the previous step and the true_labels to calculate key metrics like the AUC and plot the ROC curve.

```{r, eval = FALSE}
# Assuming 'MyNewData' has a 'study_condition' column in its SampleData
# and the true positive label is "CRC".

# Evaluate the predictions
ValidationData_filtered_qc$PredictResult$XGBoost <- EvaluateCrcBiomeScreen(
    predictions = predictions,
    true_labels = ValidationData_filtered_qc$SampleData$study_condition, # Provide the actual true labels
    TrueLabel = "CRC", # Specify the positive class label
    TaskName = "MyNewDatasetEvaluation" # A name for the output plot/files
)

# View the evaluation results
print(evaluation_results$AUC)
```

### Streamlined Screening Workflow

For users who want to run the entire screening workflow in one step, `CrcBiomeScreen` provides the `RunScreening()` function. This function encapsulates the complete process from data preparation to model validation, offering a comprehensive and easy-to-use solution.

```{r, eval = FALSE}
# Load the toy dataset from curatedMetagenomicData
data(Thomas_2018_RelativeAbundance, package = "CrcBiomeScreen")

# Create the CrcBiomeScreenObject
CrcBiomeScreenObject <- CreateCrcBiomeScreenObject(
  RelativeAbundance = Thomas_2018_RelativeAbundance[[1]]@assays@data@listData$relative_abundance,
  TaxaData = Thomas_2018_RelativeAbundance[[1]]@rowLinks$nodeLab,
  SampleData = Thomas_2018_RelativeAbundance[[1]]@colData
)

# Split the taxa into multiple levels
CrcBiomeScreenObject <- SplitTaxas(CrcBiomeScreenObject)

# Keep only the genus level data
CrcBiomeScreenObject <- KeepTaxonomicLevel(CrcBiomeScreenObject,level = "Genus")

# Inspect processed data
head(CrcBiomeScreenObject$TaxaData)

# Normalize using GMPR (Geometric Mean of Pairwise Ratios)
CrcBiomeScreenObject <- NormalizeData(CrcBiomeScreenObject, method = "GMPR", level = "Genus")

# Filter data to keep only CRC and control samples
CrcBiomeScreenObject <- FilterDataSet(
  CrcBiomeScreenObject,
  label = c("CRC", "control"),
  condition_col = "study_condition"
)

# Perform quality control using cmdscale
CrcBiomeScreenObject <- qcByCmdscale(
  CrcBiomeScreenObject,
  TaskName = "Normalize_ToyData_filtered_qc",
  normalize_method = "GMPR",
  plot = FALSE
)

# Check class balance in the training data
checkClassBalance(CrcBiomeScreenObject$SampleData$study_condition)

# Load validation data
data("ValidationData_curated")

# Create CrcBiomeScreenObject for validation data
ValidationData <- CreateCrcBiomeScreenObject(
  RelativeAbundance = ValidationData_curated[[1]]@assays@data@listData$relative_abundance,
  TaxaData = ValidationData_curated[[1]]@rowLinks$nodeLab,
  SampleData = ValidationData_curated[[1]]@colData
)

# Process validation data similarly to training data
ValidationData <- SplitTaxas(ValidationData)
ValidationData <- KeepTaxonomicLevel(ValidationData,level = "Genus")
ValidationData <- NormalizeData(ValidationData, method = "GMPR",level = "Genus")

# Ensure consistent features between training and validation data
ValidationData$NormalizedData <- ValidationData$NormalizedData[, 
  colnames(ValidationData$NormalizedData) %in% colnames(CrcBiomeScreenObject$NormalizedData)]

CrcBiomeScreenObject$NormalizedData <- CrcBiomeScreenObject$NormalizedData[, 
  colnames(CrcBiomeScreenObject$NormalizedData) %in% colnames(ValidationData$NormalizedData)]

# Filter validation data
ValidationData_filtered <- FilterDataSet(
  ValidationData,
  label = c("CRC", "control"),
  condition_col = "study_condition"
)

# Quality control for validation data
ValidationData_filtered_qc <- qcByCmdscale(
  ValidationData_filtered,
  TaskName = "Normalize_ValidationData_filtered_qc",
  normalize_method = "GMPR",
  plot = FALSE
)

# Run the complete screening workflow
ValidationData_filtered_qc <- RunScreening(
  # Input data
  obj = CrcBiomeScreenObject,
  # Model and data splitting
  model = "RF",
  partition = 0.7,
  split.requirement = list(
    label = c("control", "CRC"),
    condition_col = "study_condition"
  ),
  ClassBalance = FALSE,
  
  # Cross-validation and parallelization
  n_cv = 10,
  num_cores = 10,
  
  # Task and output naming
  TaskName = "RF_GMPR_toydata",
  
  # External validation
  ValidationData = ValidationData_filtered_qc,
  TrueLabel = "CRC"
)

# Example with XGBoost model
ValidationData_filtered_qc <- RunScreening(
  CrcBiomeScreenObject,
  model = "XGBoost",
  partition = 0.7,
  split.requirement = list(
    label = c("control", "CRC"),
    condition_col = "study_condition"
  ),
  ClassBalance = TRUE,
  n_cv = 10,
  num_cores = 10,
  TaskName = "XGBoost_GMPR_toydata",
  ValidationData = ValidationData_filtered_qc,
  TrueLabel = "CRC"
)
```

This function performs the complete workflow, including:

  * **Data normalization**: Standardizes data to a common scale.
  * **Data filtering and splitting**: Prepares the data for modeling by selecting and partitioning it into training and testing sets.
  * **Model training with cross-validation**: Trains the specified model (`RF` or `XGBoost`) using k-fold cross-validation to ensure robustness.
  * **Model evaluation on the test set**: Assesses the model's performance on a held-out test set to get an unbiased estimate of its predictive power.
  * **External validation** (if `ValidationData` is provided): Applies the trained model to an entirely independent dataset to confirm its generalizability and real-world applicability. This step also stores the individual sample predictions and evaluation metrics in the `CrcBiomeScreenObject`.
  

# Best practices and recommendations

## Normalization method selection

- **GMPR**: Recommended for most microbiome datasets, especially when dealing with compositional data and potential outliers
- **TSS**: Simpler approach, suitable for well-balanced datasets without extreme outliers

## Model selection

- **Random Forest**: Generally robust and interpretable, good baseline choice
- **XGBoost**: Often provides better performance but may require more careful hyperparameter tuning

## Validation strategies

- Always use external validation datasets when available
- Consider cross-validation for model selection and hyperparameter tuning
- Ensure consistent preprocessing between training and validation data

## Class imbalance

- Enable `ClassBalance = TRUE` when dealing with imbalanced datasets
- Monitor both sensitivity and specificity, not just overall accuracy
- Consider stratified sampling when splitting datasets

# Troubleshooting

## Common issues and solutions

### Feature mismatch between datasets
Ensure that both training and validation datasets have been processed identically and contain overlapping features.

### Memory issues with large datasets
- Reduce the number of features by applying more stringent filtering
- Use fewer CPU cores (`num_cores` parameter) to reduce memory usage

# Session information

This vignette was created under the following conditions:

```{r sessioninfo}
sessionInfo()
```

# References

If you use `CrcBiomeScreen` in your research, please cite:

[Package citation information]

For questions, bug reports, or feature requests, please visit the GitHub repository: https://github.com/iChronostasis/CrcBiomeScreen

---

**Note**: This vignette demonstrates the basic usage of `CrcBiomeScreen`. For more advanced usage and customization options, please refer to the function documentation and additional tutorials.
